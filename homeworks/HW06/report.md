# HW06 – Report

> Файл: `homeworks/HW06/report.md`  
> Важно: не меняйте названия разделов (заголовков). Заполняйте текстом и/или вставляйте результаты.

## 1. Dataset

- Какой датасет выбран: `S06-hw-dataset-02.csv`
- Размер: 18000 строк и 39 столбцов
- Целевая переменная: `target`. Классы: 0 и 1 в соотношении примерно 73.7% к 26.3%
- Признаки: все вещественные. Судя по описанию датасета и визуальному анализу, `f01`-`f35` участвуют в линейных взаимодействиях, а `x_int_1` и `x_int_2` — в нелинейных. Данные синтетические, содержат шум и перекрытие классов, что делает задачу сложной для простых моделей.

## 2. Protocol

- Разбиение: train/test в соотношении 80% к 20%, `random_state=42` (используется везде), с обязательной стратификацией (`stratify=y`) для сохранения пропорций классов в обеих выборках.
- Подбор гиперпараметров: выполнялся **только на обучающей выборке** с помощью `GridSearchCV` с `cv=5` фолдами (стратифицированная кросс-валидация). Оптимизировалась метрика **ROC-AUC**, так как она устойчива к дисбалансу и отражает качество ранжирования.
- Метрики: `accuracy`, `precision`, `recall`, `F1-score`, `ROC-AUC`. Эти метрики выбраны, потому что:
  - `accuracy` даёт общее представление, но обманчива при дисбалансе;
  - `precision` и `recall` (и их компромисс `F1`) критичны для понимания баланса между ошибками I и II рода;
  - `ROC-AUC` — основная метрика для сравнения моделей в задаче с умеренным дисбалансом, так как не зависит от порога классификации.

## 3. Models

Сравнивались следующие модели с подбором гиперпараметров на train:

- **DummyClassifier** (baseline): стратегия `most_frequent`.
- **LogisticRegression** (baseline): через пайплайн со `StandardScaler`. Подбирались тип регуляризации (`l1`, `l2`, `elasticnet`), сила (`C`), `солвер` и `max_iter`.
- **DecisionTreeClassifier**: подбирались `max_depth` ([None, 3, 5, 8]), `min_samples_leaf` ([1, 5, 10, 20]) и `ccp_alpha` ([0.0, 0.001, 0.005, 0.01]) для контроля переобучения.
- **RandomForestClassifier**: фиксировано `n_estimators=100`, подбирались `max_depth` ([3, 6, 10]) и `min_samples_leaf` ([1, 5, 10]).
- **GradientBoostingClassifier**: подбирались `n_estimators` ([50, 100]), `learning_rate` ([0.1, 0.2]) и `max_depth` ([4, 5]).
- **StackingClassifier** : использован как финальная композиция лучших экземпляров LR, RF и GB с метамоделью `LogisticRegression`. Обучен напрямую на train с `cv=5`.

## 4. Results

Финальные метрики на test:

| Metrics   | Dummy | LR     | DT     | RF     | GB     | Stack  |
|-----------|-------|--------|--------|--------|--------|--------|
| Accuracy  | 0.7375| 0.8092 | 0.8253 | 0.8669 | 0.8939 | 0.9039 |
| Precision | 0.0000| 0.7462 | 0.7365 | 0.9059 | 0.8532 | 0.8587 |
| Recall    | 0.0000| 0.4138 | 0.5206 | 0.5503 | 0.7196 | 0.7587 |
| F1-score  | 0.0000| 0.5323 | 0.6100 | 0.6847 | 0.7807 | 0.8056 |
| ROC-AUC   | 0.5000| 0.7986 | 0.8268 | 0.9151 | 0.9253 | 0.9280 |

**Победитель**: модель **Stacking** (`ROC-AUC` = 0.9280). Она показала наилучший баланс между всеми метриками, особенно высокий `recall` (75.9%) по сравнению с остальными моделями, что критично для обнаружения редкого класса.

## 5. Analysis

- **Устойчивость**: проведено 5 запуска с разными random_state (13, 90, 1024, 432, 42). Результаты по ключевым метрикам (особенно `ROC-AUC` для ансамблей) крайне стабильны (`ROC-AUC` всегда находится в пределах 0.92-0.93).
- **Ошибки**: `confusion matrix` для `Stacking`. Модель редко ошибается на классе 0 (лишь 118 FP), но пропускает 228 объектов класса 1 (FN). Это типично для задач с дисбалансом. Модель осторожна в предсказании редкого класса.`
- **Интерпретация**: `permutation importance (top 15)` для `Stacking` выявила, что **признак `f16` является доминирующим**, в то время как признаки нелинейного взаимодействия (`x_int_1`, `x_int_2`) не вошли в топ-15. Это может указывать на то, что даже сложные ансамбли иногда "упрощают" синтетическую структуру данных, полагаясь на сильные маргинальные сигналы.

## 6. Conclusion

1. Деревья решений легко переобучаются, но даже простое дерево превосходит линейные модели на нелинейных данных.
2. Ансамбли (`Random Forest`, `Gradient Boosting`) значительно улучшают качество за счёт снижения дисперсии (bagging) и смещения (boosting).
3. `Stacking` как композиция моделей даёт дополнительный прирост, демонстрируя силу мета-обучения.
4. Честный ML-протокол (фиксированный seed, стратификация, CV только на train, оценка на test один раз) критически важен для объективного сравнения.
5. `ROC-AUC` оказалась более информативной метрикой, чем `accuracy`, в условиях дисбаланса.
6. Даже на синтетических данных с заданной структурой модели могут находить неожиданные, но эффективные решения (например, опора на `f16` вместо `x_int`-признаков).