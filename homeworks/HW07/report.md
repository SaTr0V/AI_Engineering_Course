# HW07 – Report

> Файл: `homeworks/HW07/report.md`  
> Важно: не меняйте названия разделов (заголовков). Заполняйте текстом и/или вставляйте результаты.

## 1. Datasets

Выбрано 3 из 4 датасетов: №1 (`S07-hw-dataset-01.csv`), №2 (`S07-hw-dataset-02.csv`) и №3 (`S07-hw-dataset-03.csv`).

### 1.1 Dataset A

- Файл: `S07-hw-dataset-01.csv`
- Размер: (12000, 9)
- Признаки: все числовые (`f01`–`f08`)
- Пропуски: нет
- "Подлости" датасета: признаки в сильно разных масштабах (например, `f07` имеет std ≈ 59.5, а `f03` — всего ≈ 0.5), что делает обязательным масштабирование перед применением методов, основанных на евклидовых расстояниях.

### 1.2 Dataset B

- Файл: `S07-hw-dataset-02.csv`
- Размер: (8000, 4)
- Признаки: все числовые (`x1`, `x2`, `z_noise`)
- Пропуски: нет
- "Подлости" датасета: нелинейная структура (два полумесяца) + явный шумовой признак `z_noise`, который может исказить расстояния и сбить алгоритмы, основанные на евклидовой метрике.

### 1.3 Dataset C

- Файл: `S07-hw-dataset-03.csv`
- Размер: (15000, 5)
- Признаки: все числовые (`x1`, `x2`, `f_corr`, `f_noise`)
- Пропуски: нет
- "Подлости" датасета: кластеры разной плотности + фоновый шум (`f_noise`), что делает критичным выбор параметра `eps` в DBSCAN: слишком маленький `eps` разобьёт плотные кластеры, слишком большой — объединит всё в один.

## 2. Protocol

- **Препроцессинг**: для всех датасетов применён `StandardScaler` ко всем признакам (кроме `sample_id`). PCA в препроцессинге не использовалась.
- **Поиск гиперпараметров**:
  - **KMeans**: перебор `k` от 2 до 20.
  - **DBSCAN**: перебор `eps` в диапазоне от 0.2 до 2.7 с шагом 0.1–0.2 и `min_samples` от 3 до 25.
  - **Выбор "лучшего"**: по максимальному значению silhouette score.
- **Метрики**: рассчитаны `silhouette_score`, `davies_bouldin_score`, `calinski_harabasz_score`. Для DBSCAN метрики считались по всем точкам (включая шум), так как доля шума оказалась пренебрежимо мала (<0.1%).
- **Визуализация**: PCA(2D) на масштабированных данных (`X_scaled`) с раскраской по предсказанным меткам. Также создана дополнительная визуализация только по двум признакам для датасетов №2 и №3. t-SNE не использовался.

## 3. Models

Перечислите, какие модели сравнивали **на каждом датасете**, и какие параметры подбирали.

- **Dataset A (ds1)**: KMeans (`k=2..20`), DBSCAN (`eps=0.3..2.7`, `min_samples=3,5,10,15`).
- **Dataset B (ds2)**: KMeans (`k=2..10`), DBSCAN (`eps=0.2..1.5`, `min_samples=3,5,8,10`).
- **Dataset C (ds3)**: KMeans (`k=2..10`), DBSCAN (`eps=0.5..1.8`, `min_samples=10,15,20,25`).

## 4. Results

Для каждого датасета – краткая сводка результатов.

### 4.1 Dataset A

- Лучший метод и параметры: `KMeans(k=2)`
- Метрики (silhouette / DB / CH): `0.522 / 0.685 / 11786.95`
- Если был DBSCAN: доля шума = 0%
- Коротко: почему это решение выглядит разумным именно для этого датасета  
  Несмотря на визуальное наличие 4–5 групп, метрики указывают на оптимальность `k=2`. Это может быть связано с частичным перекрытием кластеров в многомерном пространстве после масштабирования. KMeans показал устойчивое и интерпретируемое разбиение.

### 4.2 Dataset B

- Лучший метод и параметры: `DBSCAN(eps=1.2, min_samples=10)`
- Метрики (silhouette / DB / CH): `0.548 / 6.662 / 1.414`
- Если был DBSCAN: доля шума = 0.0625%
- Коротко: почему это решение выглядит разумным именно для этого датасета  
  DBSCAN смог лучше KMeans справиться с нелинейной структурой, несмотря на влияние шумового признака `z_noise`. Высокий silhouette score подтверждает, что найденные кластеры компактны и хорошо разделены.

### 4.3 Dataset C

- Лучший метод и параметры: `DBSCAN(eps=1.2, min_samples=15)`
- Метрики (silhouette / DB / CH): `0.492 / 3.436 / 1.768`
- Если был DBSCAN: доля шума = 0.013%
- Коротко: почему это решение выглядит разумным именно для этого датасета  
  DBSCAN корректно выделил кластеры разной плотности, почти не затронув фоновый шум. PCA-визуализация подтверждает, что найдено 5 чётких групп, соответствующих исходной структуре данных.

## 5. Analysis

### 5.1 Сравнение алгоритмов (важные наблюдения)

- **KMeans "ломается"** на нелинейных структурах (Dataset B), так как он ищет сферические кластеры и не может адекватно разделить полумесяцы.
- **DBSCAN выигрывает** там, где важна форма и плотность (Datasets B и C), но требует тщательного подбора `eps`.
- **Сильнее всего на результат повлияло**:
  - Для Dataset A — разница в масштабах признаков (без scaling результаты "едут");
  - Для Dataset B — наличие шумового признака и нелинейность;
  - Для Dataset C — разная плотность кластеров.

### 5.2 Устойчивость (обязательно для одного датасета)

- Какую проверку устойчивости делали: 5 запусков KMeans с разными `random_state` на Dataset A (`k=2`).
- Что получилось: все попарные значения ARI равны 1.0.
- Вывод: решение **абсолютно устойчиво**, так как KMeans всегда сходится к одному и тому же глобальному минимуму на этом датасете.

### 5.3 Интерпретация кластеров

Для Dataset A кластеры компактны и хорошо разделены.

Для Dataset B едва различается видно форма полумесяцев из-за шума.

Для Dataset C удалось выделить все 5 блобов разной плотности, что подтверждается как метриками, так и визуализацией.

## 6. Conclusion

- Ни один алгоритм кластеризации не является универсальным — выбор зависит от гипотезы о структуре данных.
- Масштабирование обязательно для distance-based методов при разных масштабах признаков.
- Внутренние метрики (особенно silhouette) — мощный инструмент для сравнения моделей, но они не всегда совпадают с визуальной "правдой".
- DBSCAN эффективен для нелинейных структур и кластеров разной плотности, но чувствителен к параметрам.
- Честный unsupervised-эксперимент требует единого протокола: фиксированный препроцессинг, решётчатый поиск, единые метрики и визуализацию.
- Даже при знании истинной структуры данных автоматический выбор модели может дать субъективно "неожиданный" результат — это нормально и отражает сложность unsupervised-задач.